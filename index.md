---
layout: default
---



## About Me

<img class="profile-picture" src="picture.jpg">

Hi! I graduated in Applied Mathematics and Computer Science from [Ponts Paristech](http://www.enpc.fr/) and obtained with Honors the Master program([MVA](http://www.math.ens-cachan.fr/version-francaise/formations/master-mva/contenus-/master-mva-cours-2016-2017-161721.kjsp?RH=1242415112528)) in **Computer Vision and Machine Learning** at ENS Paris Saclay. I am now between the LSCP and NPI at ENS Paris under the supervision of [Pr. Emmanuel Dupoux](http://www.lscp.net/persons/dupoux/index.html) and [Pr. Anne-Catherine Bachoud-Lévi](http://www.imrb.inserm.fr/equipes/ac-bachoud-levi/).


## Research

I want to understand the trajectories through the lifespan of human and animal capabilities to understand the world and communicate with their peers. What are the neural and algorithmic computations that give rise to these amazing capabilities during infancy? How are these perceptual, cognitive and social skills affected by aging, neurodegenerative diseases or interventions?

Living systems are immersed in diverse, noisy environments and need to find the relevant signal to build adaptive strategies to survive. What is the sensory information that is useful to learn, navigate in and interact with the word? How to accurately measure the state of knowledge in ecological settings, outside the controlled conditions of the laboratory? Ultimately, I seek to build the algorithms that measure **and** match the performances of living systems in these naturalistic conditions. Can we build models of these living organisms? How can these findings help in education and medicine?

I also try to construct better machine learning and signal processing algorithms that match the performance of humans in naturalistic conditions. In return, this should yield more reliable methods to measure ecological behaviors and better models of human cognition.

My PhD project focuses on the **measure** of the motor, cognitive and emotional capabilities of individuals affected by Huntington's Disease. We build the algorithms to automatically measure the spoken language productions, as it invokes a combination of these skills and remain ecological to collect from a clinical point of view. 

## Publications

**Learning Strides in Convolutional Neural Networks.**
Rachid Riad, Olivier Teboul, David Grangier, Neil Zeghidour. Spotlight at International Conference on Learning Representations, 2022.
[paper](https://github.com/Rachine/Rachine.github.io/data/Papers/strides2022riadGoogle.pdf)[code](https://github.com/google-research/diffstride)


**Learning spectro-temporal representations of complex sounds with parameterized neural networks.**
Rachid Riad, Julien Karadayi, Anne-Catherine Bachoud-Lévi and Emmanuel Dupoux. The Journal of the Acoustical Society of America, 2021.
[paper](https://github.com/Rachine/Rachine.github.io/data/Papers/jasa2021.pdf)/[code](https://github.com/bootphon/learnable-strf)/[slides](https://www.rocq.inria.fr/semdoc/Presentations/20210316_RachidRiad.pdf)

**pygamma-agreement: Gamma γ measure for inter/intra-annotator agreement in Python.**
Hadrien Titeux and Rachid Riad. Journal of Open Source Software, 2021.
[paper](hhttps://joss.theoj.org/papers/10.21105/joss.02989)/[code](https://github.com/bootphon/pygamma-agreement)

**Vocal markers from sustained phonation in Huntington's Disease**
Rachid Riad, Hadrien Titeux, Laurie Lemoine, Justine Montillot, Jennifer Hamet Bagnou, Xuan-Nga Cao, Emmanuel Dupoux, Anne-Catherine Bachoud-Lévi
.  In *Proc. Interspeech* 2020, Shangai, China, September 2020.
[paper](https://arxiv.org/abs/2006.05365)/[code](https://github.com/bootphon/sustained-phonation-features)

**Identification of primary and collateral tracks in stuttered speech**
Rachid Riad, Anne-Catherine Bachoud-Lévi, Frank Rudzicz, Emmanuel Dupoux
.  In *Proc. LREC* 2020, Marseille, France, May 2020.
[paper](https://arxiv.org/abs/2003.01018)


**Seshat: A tool for managing and verifying annotation campaigns of audio data**
Hadrien Titeux\*, Rachid Riad\*, Xuan-Nga Cao, Nicolas Hamilakis, Kris Madden, Alejandrina Cristia, Anne-Catherine Bachoud-Lévi, Emmanuel Dupoux
.  In *Proc. LREC* 2020, Marseille, France, May 2020.
[paper](https://arxiv.org/abs/2003.01472)/[code](https://github.com/bootphon/seshat)/[documentation](https://seshat-annotation.readthedocs.io/en/latest/)

**Sampling strategies in siamese networks for unsupervised speech representation learning.**
Rachid Riad, Corentin Dancette, Julien Karadayi, Neil Zeghidour, Thomas Schatz, and Emmanuel Dupoux.  In *Proc. Interspeech* 2018, Hyderabad, India, September 2018.
[paper](https://arxiv.org/pdf/1804.11297)/[code](https://github.com/bootphon/abnet3)/[experiments](https://github.com/rachine/sampling_siamese2018)/[slides](https://github.com/Rachine/sampling_siamese2018/blob/master/Presentation_Sampling_Interspeech_2018_slides.pdf)

**Learning Word Embeddings: Unsupervised Methods for Fixed-size Representations of Variable-length Speech Segments** [paper](http://www.lscp.net/persons/dupoux/papers/Holzenberger_DKRD_2018_fixed_length_embeddings_for_words.Interspeech.pdf)
Nils Holzenberger, Mingxing Du, Julien Karadayi, Rachid Riad, and Emmanuel Dupoux.  In *Proc. Interspeech* 2018, Hyderabad, India, September 2018.

**Linguistic unit discovery from multi-modal inputs in unwritten languages: Summary of the" Speaking Rosetta" JSALT 2017 Workshop**, [paper](https://arxiv.org/pdf/1802.05092) Odette Scharenborg, Laurent Besacier, Alan Black, Mark Hasegawa-Johnson, Florian Metze, Graham Neubig, Sebastian Stüker, Pierre Godard, Markus Müller, Lucas Ondel, Shruti Palaskar, Philip Arthur, Francesco Ciannella, Mingxing Du, Elin Larsen, Danny Merkx, Rachid Riad, Liming Wang and Emmanuel Dupoux. IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Apr 2018, Calgary, Alberta, Canada

## Software

Together with [Corentin Dancette](https://cdancette.fr/), we developed the third version of the Siamese network toolbox [ABnet3](https://github.com/bootphon/abnet3) for weakly/unsupervised representation learning of speech signals.


<!-- ## Experience


Here are some experiences.

Year | Position | Topic
-----|-------|--------
2018 | Research assistant @ [SPOClab/ Vector Institute, University of Toronto](http://vectorinstitute.ai/) | Health assessment through speech technologies
2018 | Research assistant @ [LSCP & NPI/ ENS](https://npi.dec.ens.fr/) | Health assessment through speech technologies
2017 | Research intern @ [LSCP / ENS](http://www.lscp.net/index.php) | Machine learning meets language and cognitive development : How do babies learn their first language?
2016 | Software Engineer @ [MapJam](https://mapjam.com) | Building GIS Stack and complex mapping applications
2015 | Software Engineer intern @ [Vehicle Data Science](https://www.crunchbase.com/organization/vehicle-data-science#/entity) | Data visualization with D3.js and Leaflet.js
2014 | Research intern @ [Cermics](http://cermics.enpc.fr/) | Study of financial Mathematics models

<!-- ---

Here is a blockquote

<!-- > To a great mind, nothing is little -->

<!-- ## References

* Available upon request -->

I got all inspiration from a jekyll based resume template. You can find the full source code on [GitHub](https://github.com/bk2dcradle/researcher) and my version [GitHub](https://github.com/Rachine/Rachine.github.io)
